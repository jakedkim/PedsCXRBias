{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training 25 aggregate models \n",
    "import pandas as pd \n",
    "import os \n",
    "import numpy as np\n",
    "import subprocess\n",
    "\n",
    "# File paths and setup\n",
    "parent = '/home/jkim/research/peds_cxr/'\n",
    "# Predefined 25 random seeds\n",
    "predefined_seeds = [9,17,18,29,30,34,41,42,51,52,61,66,74,75,78,81,84,86,87,89,90,92,96,98,99]\n",
    "\n",
    "### set source\n",
    "metadata_source = parent + '25variation/metadata/final/aggregate/' \n",
    "\n",
    "for seed in predefined_seeds:\n",
    "    image_source = parent + '25variation/images/aggregate/aggregate_' + str(seed)\n",
    "    # Load the data from the CSV file into a pandas DataFrame\n",
    "    aggregate_metadata_path = metadata_source + f'/aggregate_metadata_seed_{seed}.csv'\n",
    "    aggregate_metadata = pd.read_csv(aggregate_metadata_path)\n",
    "\n",
    "    # Creating image_paths.txt\n",
    "    image_path = aggregate_metadata['Image Index']\n",
    "    output_image_txt = image_source + '/image_paths.txt'\n",
    "    image_path.to_csv(output_image_txt, sep=',', index=False, header=False)\n",
    "\n",
    "    # Creating train.txt \n",
    "    train_index = aggregate_metadata[aggregate_metadata['Set']=='train']\n",
    "    aggregate_train_output = image_source + '/train.txt'\n",
    "    aggregate_train_txt = train_index['Image Index'] \n",
    "    aggregate_train_txt.to_csv(aggregate_train_output, sep=',', index=False, header=False)\n",
    "\n",
    "    # Creating val.txt \n",
    "    val_index = aggregate_metadata[aggregate_metadata['Set']=='val']\n",
    "    aggregate_val_output = image_source + '/val.txt'\n",
    "    aggregate_val_txt = val_index['Image Index'] \n",
    "    aggregate_val_txt.to_csv(aggregate_val_output, sep=',', index=False, header=False)\n",
    "\n",
    "    # Creating test.txt\n",
    "    test_index = aggregate_metadata[aggregate_metadata['Set']=='test']\n",
    "    aggregate_test_output = image_source + '/aggregate_test.txt'\n",
    "    aggregate_test_txt = test_index['Image Index'] \n",
    "    aggregate_test_txt.to_csv(aggregate_test_output, sep=',', index=False, header=False)\n",
    "\n",
    "    # Creating labels.csv\n",
    "    aggregate_labels_output = image_source + '/labels.csv'\n",
    "    aggregate_labels = aggregate_metadata[['Image Index', 'No Finding', 'Cardiomegaly', 'Consolidation', 'Infiltration', 'Pneumonia', 'Mass/Nodule']]\n",
    "    \n",
    "    # rename Image Index to Image\n",
    "    aggregate_labels = aggregate_labels.rename(columns={'Image Index': 'Image'})\n",
    "    aggregate_labels.to_csv(aggregate_labels_output, sep=',', index=False)\n",
    "\n",
    "    # confirming the number of train val and test. \n",
    "    print(\"# of train:\",len(aggregate_train_txt))\n",
    "    print('# of val:',len(aggregate_val_txt))\n",
    "    print('# of test:',len(aggregate_test_txt))\n",
    "    print('# of image path:',len(image_path))\n",
    "    print('# of labels:',len(aggregate_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create json file. \n",
    "import json\n",
    "import os\n",
    "\n",
    "# Base JSON content template\n",
    "json_template = {\n",
    "    \"data_dir\": \"/home/jkim/research/peds_cxr/25variation/images/aggregate/\",\n",
    "    \"labels\": [\"No Finding\", \"Cardiomegaly\", \"Consolidation\", \"Infiltration\", \"Mass/Nodule\", \"Pneumonia\"],\n",
    "    \"dataset_nicenames\": {\n",
    "        \"nihcxr14_test\": \"NIH CXR14\",\n",
    "        \"chexpert_test\": \"CheXpert\",\n",
    "        \"mimic_test\": \"MIMIC\",\n",
    "        \"padchest_test\": \"PadChest\",\n",
    "        \"rsna_pneumonia_test_100\": \"RSNA Pneumonia\",\n",
    "        \"rsna_pneumonia_DeiT-B_test_100\": \"RSNA Pneumonia DeiT-B\",\n",
    "        \"Aggregate_DenseNet121_aggregate_test\": \"aggregate DenseNet121\",\n",
    "        \"Aggregate_DenseNet121_aggregate_test\": \"Aggregate DenseNet121\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Loop through each seed to generate JSON files\n",
    "for seed in predefined_seeds:\n",
    "    # Construct the new directory path\n",
    "    new_data_dir = f\"/home/jkim/research/peds_cxr/25variation/images/aggregate/aggregate_{seed}/\"\n",
    "    \n",
    "    # Create the new directory if it doesn't exist\n",
    "    if not os.path.exists(new_data_dir):\n",
    "        print(f\"The directory {new_data_dir} does not exist. Creating it.\")\n",
    "        os.makedirs(new_data_dir)\n",
    "\n",
    "    # Specify the path for the new JSON file\n",
    "    new_json_path = os.path.join(new_data_dir, f\"cfg_aggregate_{seed}.json\")\n",
    "\n",
    "    # Write the JSON file\n",
    "    with open(new_json_path, 'w') as f:\n",
    "        json.dump(json_template, f, indent=4)\n",
    "    \n",
    "    print(f\"Created new JSON file at {new_json_path}\")\n",
    "\n",
    "# batch creating result directiory\n",
    "for seed in predefined_seeds:\n",
    "    # Construct the new directory path for results\n",
    "    new_result_dir = f\"/home/jkim/research/peds_cxr/25variation/results/aggregate/train/aggregate_{seed}/\"\n",
    "    \n",
    "    # Create the new directory if it doesn't exist\n",
    "    if not os.path.exists(new_result_dir):\n",
    "        os.makedirs(new_result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of hyperparameters to test\n",
    "optimizers = ['SGD','AdamW'] \n",
    "initial_lrs = [5e-3, 1e-2, 5e-2, 1e-1]\n",
    "weight_decays = [0, 1e-5, 1e-4, 1e-3]\n",
    "dropouts = [0, 0.5]\n",
    "gpu='1' \n",
    "\n",
    "# Iterate over the hyperparameters\n",
    "for seed in ['42']:    \n",
    "    for optimizer in optimizers:\n",
    "        for initial_lr in initial_lrs:\n",
    "            for weight_decay in weight_decays:\n",
    "                for dropout in dropouts:\n",
    "                    # Construct the command with updated hyperparameters\n",
    "                    command = [\n",
    "                        'python3',\n",
    "                        parent + 'transformer-radiographs/train_cxr.py',\n",
    "                        '--cfg-dir',\n",
    "                        parent + f'25variation/images/aggregate/aggregate_{seed}/cfg_aggregate_{seed}.json',\n",
    "                        '--dataset',\n",
    "                        f'aggregate_{seed}',\n",
    "                        '--labels-set',\n",
    "                        'labels',\n",
    "                        '--architecture',\n",
    "                        'DenseNet121',\n",
    "                        '--results-dir',\n",
    "                        parent + '25variation/results/aggregate/train/aggregate_' + str(seed),\n",
    "                        '--optimizer-family',\n",
    "                        optimizer,\n",
    "                        '--dropout',\n",
    "                        str(dropout),\n",
    "                        '--weight-decay',\n",
    "                        str(weight_decay),\n",
    "                        '--initial-lr',\n",
    "                        str(initial_lr),\n",
    "                        '--drop-factor',\n",
    "                        '0.1',\n",
    "                        '--plateau-patience',\n",
    "                        '3',\n",
    "                        '--plateau-threshold',\n",
    "                        '1e-4',\n",
    "                        '--break-patience',\n",
    "                        '5',\n",
    "                        '--train-transform',\n",
    "                        'peds',\n",
    "                        '--train-file',\n",
    "                        'train.txt',\n",
    "                        '--val-file',\n",
    "                        'val.txt',\n",
    "                        '--use-gpus',\n",
    "                        gpu\n",
    "                    ]\n",
    "\n",
    "                    # Execute the command\n",
    "                    subprocess.run(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training 25 aggregate models - DenseNet121_lr0.01_bs16_optSGD_wd1e-05_sch_step_pp3_bp5_trtrain.txt_vaval.txt_tfpeds_nlbatch_do0.5_1708401545.txt\n",
    "optimizers = ['SGD']\n",
    "initial_lrs = [0.01]\n",
    "weight_decays = [1e-5]\n",
    "dropouts = [0.5]\n",
    "gpu='0' \n",
    "\n",
    "parent = '/home/jkim/research/peds_cxr/'\n",
    "import subprocess\n",
    "# Iterate over the hyperparameters\n",
    "for seed in predefined_seeds:    \n",
    "    for optimizer in optimizers:\n",
    "        for initial_lr in initial_lrs:\n",
    "            for weight_decay in weight_decays:\n",
    "                for dropout in dropouts:\n",
    "                    # Construct the command with updated hyperparameters\n",
    "                    command = [\n",
    "                        'python3',\n",
    "                        parent + 'transformer-radiographs/train_cxr.py',\n",
    "                        '--cfg-dir',\n",
    "                        parent + f'25variation/images/aggregate/aggregate_{seed}/cfg_aggregate_{seed}.json',\n",
    "                        '--dataset',\n",
    "                        f'aggregate_{seed}',\n",
    "                        '--labels-set',\n",
    "                        'labels',\n",
    "                        '--architecture',\n",
    "                        'DenseNet121',\n",
    "                        '--results-dir',\n",
    "                        parent + '25variation/results/aggregate/train/aggregate_' + str(seed),\n",
    "                        '--optimizer-family',\n",
    "                        optimizer,\n",
    "                        '--dropout',\n",
    "                        str(dropout),\n",
    "                        '--weight-decay',\n",
    "                        str(weight_decay),\n",
    "                        '--initial-lr',\n",
    "                        str(initial_lr),\n",
    "                        '--drop-factor',\n",
    "                        '0.1',\n",
    "                        '--plateau-patience',\n",
    "                        '3',\n",
    "                        '--plateau-threshold',\n",
    "                        '1e-4',\n",
    "                        '--break-patience',\n",
    "                        '5',\n",
    "                        '--train-transform',\n",
    "                        'peds',\n",
    "                        '--train-file',\n",
    "                        'train.txt',\n",
    "                        '--val-file',\n",
    "                        'val.txt',\n",
    "                        '--use-gpus',\n",
    "                        gpu\n",
    "                    ]\n",
    "\n",
    "                    # Execute the command\n",
    "                    subprocess.run(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing 25 aggregate models - DenseNet121_lr0.01_bs16_optSGD_wd1e-05_sch_step_pp3_bp5_trtrain.txt_vaval.txt_tfpeds_nlbatch_do0.5_1705144996.txt\n",
    "import subprocess\n",
    "import pandas as pd \n",
    "import os\n",
    "import glob\n",
    "\n",
    "predefined_seeds = [9,17,18,29,30,34,41,42,51,52,61,66,74,75,78,81,84,86,87,89,90,92,96,98,99]\n",
    "# batch creating result directiory\n",
    "for seed in predefined_seeds:\n",
    "    for dir in ['all', 'M', 'F']:\n",
    "        # Construct the new directory path for results\n",
    "        new_result_dir = parent + f\"25variation/results/aggregate/test/{dir}/aggregate_{seed}_{dir}/\"\n",
    "        \n",
    "        # Create the new directory if it doesn't exist\n",
    "        if not os.path.exists(new_result_dir):\n",
    "            os.makedirs(new_result_dir)\n",
    "\n",
    "for seed in predefined_seeds:\n",
    "    aggregate_metadata_path = parent + '25variation/metadata/final/aggregate/aggregate_metadata_seed_' + str(seed) + '.csv'\n",
    "    aggregate_metadata = pd.read_csv(aggregate_metadata_path)\n",
    "\n",
    "    # Creating aggregate_test_male / female .txt\n",
    "    sexs = ['M', 'F']\n",
    "    for sex in sexs:\n",
    "        test_index = aggregate_metadata[(aggregate_metadata['Set'] == 'test') & (aggregate_metadata['Patient Gender'] == sex)]\n",
    "        image_source = parent + '25variation/images/aggregate/aggregate_' + str(seed) + '/'\n",
    "        aggregate_test_output = image_source + 'aggregate_test_'+ sex +'.txt'\n",
    "        aggregate_test_txt = test_index['Image Index']\n",
    "        aggregate_test_txt.to_csv(aggregate_test_output, sep=',', index=False, header=False)\n",
    "    \n",
    "for seed in predefined_seeds:\n",
    "    # Build the pattern to search for model files\n",
    "    search_pattern = os.path.join(parent, f\"25variation/results/aggregate/train/aggregate_{seed}/DenseNet121_lr0.01_bs16_optSGD_wd1e-05_sch_step_pp3_bp5_trtrain.txt_vaval.txt_tfpeds_nlbatch_do0.5_*_model.pt\")\n",
    "    \n",
    "    # Use glob to find the file\n",
    "    matching_files = glob.glob(search_pattern)\n",
    "    \n",
    "    # Check if any matching files are found\n",
    "    if not matching_files:\n",
    "        print(f\"No matching model files found for seed {seed}.\")\n",
    "        continue  # Skip to the next iteration\n",
    "\n",
    "    # Take the first matching file\n",
    "    model_file_path = matching_files[0]\n",
    "\n",
    "    image_source = parent + f'25variation/images/aggregate/aggregate_{seed}/'\n",
    "    command = [\n",
    "        \"python3\",\n",
    "        parent + \"transformer-radiographs/test_cxr.py\",\n",
    "        \"--cfg-dir\", parent + f\"25variation/images/aggregate/aggregate_{seed}/cfg_aggregate_{seed}.json\",\n",
    "        \"--dataset\", f'aggregate_{seed}',\n",
    "        \"--labels-set\", \"labels\",\n",
    "        \"--model-state\", model_file_path,\n",
    "        \"--model-type\", \"DenseNet121\",\n",
    "        \"--results-dir\", parent + f\"25variation/results/aggregate/test/all/aggregate_{seed}_all\",\n",
    "        \"--test-file\", image_source + \"aggregate_test.txt\",\n",
    "        \"--use-gpus\", gpu\n",
    "    ]\n",
    "\n",
    "    # Run the command\n",
    "    try:\n",
    "        subprocess.run(command, check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"An error occurred while executing the command: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing 25 aggregate models - DenseNet121_lr0.01_bs16_optSGD_wd1e-05_sch_step_pp3_bp5_trtrain.txt_vaval.txt_tfpeds_nlbatch_do0.5_1705144996.txt\n",
    "import os\n",
    "import subprocess\n",
    "import pandas as pd \n",
    "import glob\n",
    "\n",
    "sexs = ['M', 'F']\n",
    "# Testing M vs F\n",
    "for sex in sexs:\n",
    "    for seed in predefined_seeds:\n",
    "    # Build the pattern to search for model files\n",
    "        search_pattern = os.path.join(parent, f\"25variation/results/aggregate/train/aggregate_{seed}/DenseNet121_lr0.01_bs16_optSGD_wd1e-05_sch_step_pp3_bp5_trtrain.txt_vaval.txt_tfpeds_nlbatch_do0.5_*_model.pt\")\n",
    "        \n",
    "        # Use glob to find the file\n",
    "        matching_files = glob.glob(search_pattern)\n",
    "        \n",
    "        # Check if any matching files are found\n",
    "        if not matching_files:\n",
    "            print(f\"No matching model files found for seed {seed}.\")\n",
    "            continue  # Skip to the next iteration\n",
    "\n",
    "        # Assuming there's only one matching file, take the first one\n",
    "        model_file_path = matching_files[0]\n",
    "\n",
    "        image_source = parent + f'25variation/images/aggregate/aggregate_{seed}/' \n",
    "        command = [\n",
    "            \"python3\",\n",
    "            parent + \"transformer-radiographs/test_cxr.py\",\n",
    "            \"--cfg-dir\", parent + f\"25variation/images/aggregate/aggregate_{seed}/cfg_aggregate_{seed}.json\",\n",
    "            \"--dataset\", f'aggregate_{seed}',\n",
    "            \"--labels-set\", \"labels\",\n",
    "            \"--model-state\", model_file_path,\n",
    "            \"--model-type\", \"DenseNet121\",\n",
    "            \"--results-dir\", parent + f\"25variation/results/aggregate/test/{sex}/aggregate_{seed}_{sex}\",\n",
    "            \"--test-file\", image_source + \"aggregate_test_\" + sex + \".txt\",\n",
    "            \"--use-gpus\", gpu\n",
    "    ]\n",
    "\n",
    "        # Run the command\n",
    "        try:\n",
    "            subprocess.run(command, check=True)\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"An error occurred while executing the command: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import os \n",
    "import glob\n",
    "\n",
    "# setting directories\n",
    "parent = '/home/jkim/research/peds_cxr/'\n",
    "\n",
    "sexs = ['all','M','F']\n",
    "sex_file_name = ['', '_M', '_F']\n",
    "for sex, sex_name in zip(sexs, sex_file_name):\n",
    "    for seed in predefined_seeds:\n",
    "        # Build the pattern to search for model files\n",
    "            search_pattern = os.path.join(parent, f\"25variation/results/aggregate/test/{sex}/aggregate_{seed}_{sex}/DenseNet121_lr0.01_bs16_optSGD_wd1e-05_sch_step_pp3_bp5_trtrain.txt_vaval.txt_tfpeds_nlbatch_do0.5_*.pkl\")\n",
    "        \n",
    "            # Use glob to find the file\n",
    "            matching_files = glob.glob(search_pattern)\n",
    "            \n",
    "            # Check if any matching files are found\n",
    "            if not matching_files:\n",
    "                print(f\"No matching model files found for seed {seed}.\")\n",
    "                continue  # Skip to the next iteration\n",
    "\n",
    "            pkl_directory = matching_files[0]\n",
    "\n",
    "            directory = parent + f'25variation/results/aggregate/unpickle/{sex}/'\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "\n",
    "            # Open the pickle file and load the data\n",
    "            with open(pkl_directory, \"rb\") as f:\n",
    "                data = pickle.load(f)\n",
    "\n",
    "            # Extract the nested dictionary\n",
    "            nested_dict = data.get(f'aggregate_{seed}_DenseNet121_aggregate_test{sex_name}', {})\n",
    "\n",
    "            # Create a DataFrame from the nested dictionary with keys 'y', 'yhat', and 'file'\n",
    "            df_nested = pd.DataFrame({\n",
    "                \"y\": nested_dict[\"y\"],\n",
    "                \"yhat\": nested_dict[\"yhat\"],\n",
    "                \"file\": nested_dict[\"file\"]\n",
    "            })\n",
    "\n",
    "            # Define the file path\n",
    "            nested_file_path = directory + f'aggregate_{seed}_{sex}_pkl.csv'\n",
    "\n",
    "            # Save the DataFrame to a CSV file\n",
    "            df_nested.to_csv(nested_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Pkl file as csv file \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, roc_curve\n",
    "import ast\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "parent = '/home/jkim/research/peds_cxr/'\n",
    "\n",
    "# Changing pickle file from dictionary format to list format \n",
    "sexs = ['all', 'M', 'F']\n",
    "\n",
    "# create AUC directory in results\n",
    "if not os.path.exists(parent + '25variation/results/aggregate/analysis/'):\n",
    "    os.makedirs(parent + '25variation/results/aggregate/analysis/')\n",
    "if not os.path.exists(parent + '25variation/results/aggregate/analysis/plot/all'):\n",
    "    os.makedirs(parent + '25variation/results/aggregate/analysis/plot/all')\n",
    "if not os.path.exists(parent + '25variation/results/aggregate/analysis/plot/MF'):\n",
    "    os.makedirs(parent + '25variation/results/aggregate/analysis/plot/MF')\n",
    "if not os.path.exists(parent + '25variation/results/aggregate/analysis/csv'):\n",
    "    os.makedirs(parent + '25variation/results/aggregate/analysis/csv')\n",
    "\n",
    "for sex in sexs: \n",
    "    if not os.path.exists(parent + f'25variation/results/aggregate/analysis/unpickledcsv/{sex}'):\n",
    "        os.makedirs(parent + f'25variation/results/aggregate/analysis/unpickledcsv/{sex}')  \n",
    "\n",
    "for seed in predefined_seeds:        \n",
    "    for sex in sexs: \n",
    "        # set directories\n",
    "        pkl_dir = parent + f'25variation/results/aggregate/unpickle/{sex}/aggregate_{seed}_{sex}_pkl.csv'\n",
    "\n",
    "        # Loading the pkl file\n",
    "        aggregate_pkl = pd.read_csv(pkl_dir)\n",
    "\n",
    "        # Defining the aggregate_label as the list of labels\n",
    "        aggregate_label = [\"No Finding\", \"Cardiomegaly\", \"Consolidation\", \"Infiltration\", \"Mass/Nodule\", \"Pneumonia\"]\n",
    "\n",
    "        # Converting the string representation of lists to actual lists\n",
    "        aggregate_pkl['y'] = aggregate_pkl['y'].apply(ast.literal_eval)\n",
    "        aggregate_pkl['yhat'] = aggregate_pkl['yhat'].apply(ast.literal_eval)\n",
    "\n",
    "        # Splitting the one-hot encoded labels and predictions into separate columns\n",
    "        y_true_df = pd.DataFrame(aggregate_pkl['y'].tolist(), columns=aggregate_label)\n",
    "        y_pred_df = pd.DataFrame(aggregate_pkl['yhat'].tolist(), columns=aggregate_label)\n",
    "\n",
    "        # Merging the true labels and predicted probabilities based on index\n",
    "        result_df = pd.concat([y_true_df, y_pred_df.add_suffix('_pred')], axis=1)\n",
    "\n",
    "        # Saving\n",
    "        result_df.to_csv(parent + f'25variation/results/aggregate/analysis/unpickledcsv/{sex}/aggregate_{seed}_{sex}_pkl.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats and plotting for all aggregate data \n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, auc\n",
    "from scipy.stats import sem\n",
    "\n",
    "# Initialize variables\n",
    "base_file_path = parent + \"/25variation/results/aggregate/analysis/unpickledcsv/all/\"\n",
    "labels = [\"No Finding\", \"Cardiomegaly\", \"Consolidation\", \"Infiltration\", \"Mass/Nodule\", \"Pneumonia\"]\n",
    "all_metrics = {label: [] for label in labels}\n",
    "all_metrics['All Label'] = []\n",
    "\n",
    "# Initialize the dictionary to hold universal thresholds for each label\n",
    "universal_thresholds = {label: {} for label in labels}\n",
    "\n",
    "# Base file paths for male and female CSV files\n",
    "base_file_path_M = parent + \"25variation/results/aggregate/analysis/unpickledcsv/M/aggregate_{seed}_M_pkl.csv\"\n",
    "base_file_path_F = parent + \"25variation/results/aggregate/analysis/unpickledcsv/F/aggregate_{seed}_F_pkl.csv\"\n",
    "base_file_path_all = parent + \"25variation/results/aggregate/analysis/unpickledcsv/all/aggregate_{seed}_all_pkl.csv\"\n",
    "\n",
    "# Loop through all seeds\n",
    "for seed in predefined_seeds:\n",
    "    file_path = os.path.join(parent, f\"25variation/results/aggregate/analysis/unpickledcsv/all/aggregate_{seed}_all_pkl.csv\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    for label in labels:\n",
    "        true_labels = df[f'{label}']\n",
    "        predicted_scores = df[f'{label}_pred']\n",
    "        \n",
    "        # Calculate ROC curve and AUC\n",
    "        fpr, tpr, thresholds = roc_curve(true_labels, predicted_scores)\n",
    "                \n",
    "        # Calculating Youden's Index to find the optimal threshold\n",
    "        youden_index = tpr + (1 - fpr) - 1\n",
    "        optimal_idx = np.argmax(youden_index)\n",
    "        optimal_threshold = thresholds[optimal_idx]\n",
    "        \n",
    "        # Store this optimal threshold for this label and seed\n",
    "        universal_thresholds[label][seed] = optimal_threshold\n",
    "\n",
    "def calculate_metrics_and_auroc(df, label, optimal_threshold):\n",
    "    true_labels = df[label]\n",
    "    predicted_scores = df[f\"{label}_pred\"]\n",
    "    \n",
    "    # Calculate AUROC\n",
    "    auroc = roc_auc_score(true_labels, predicted_scores)\n",
    "    \n",
    "    # Other metrics\n",
    "    predicted_labels = (predicted_scores >= optimal_threshold).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(true_labels, predicted_labels).ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    ppv = tp / (tp + fp) if tp + fp != 0 else 0\n",
    "    npv = tn / (tn + fn) if tn + fn != 0 else 0\n",
    "    f1_score = 2 * (ppv * sensitivity) / (ppv + sensitivity) if ppv + sensitivity != 0 else 0\n",
    "    fpr = fp / (fp + tn)  \n",
    "    fnr = fn / (fn + tp)\n",
    "    \n",
    "    return [auroc, sensitivity, specificity, ppv, npv, f1_score, fpr, fnr, optimal_threshold]\n",
    "\n",
    "# Initialize empty DataFrames for storing metrics\n",
    "cols = ['Seed', 'Label', 'AUROC', 'Sensitivity', 'Specificity', 'PPV', 'NPV', 'F1 Score', 'FPR', 'FNR', 'Youden_Threshold'] \n",
    "metrics_M_df = pd.DataFrame(columns=cols)\n",
    "metrics_F_df = pd.DataFrame(columns=cols)\n",
    "metrics_all_df = pd.DataFrame(columns=cols)\n",
    "\n",
    "# Loop through all seeds\n",
    "for seed in predefined_seeds:\n",
    "    df_male = pd.read_csv(base_file_path_M.format(seed=seed))\n",
    "    df_female = pd.read_csv(base_file_path_F.format(seed=seed))\n",
    "    df_all = pd.read_csv(base_file_path_all.format(seed=seed))\n",
    "\n",
    "    metrics_M_all_label = []\n",
    "    metrics_F_all_label = []\n",
    "    metrics_all_all_label = []\n",
    "\n",
    "    for label in labels:\n",
    "        optimal_threshold = universal_thresholds[label][seed]\n",
    "        \n",
    "        # Calculate metrics for male and female\n",
    "        metrics_M = calculate_metrics_and_auroc(df_male, label, optimal_threshold)\n",
    "        metrics_F = calculate_metrics_and_auroc(df_female, label, optimal_threshold)\n",
    "        metrics_all = calculate_metrics_and_auroc(df_all, label, optimal_threshold)\n",
    "\n",
    "        # Store metrics for \"All Label\" calculation\n",
    "        metrics_M_all_label.append(metrics_M)\n",
    "        metrics_F_all_label.append(metrics_F)\n",
    "        metrics_all_all_label.append(metrics_all)\n",
    "\n",
    "        # Append to DataFrame\n",
    "        metrics_M_df = metrics_M_df.append(pd.Series([seed, label] + metrics_M, index=cols), ignore_index=True)\n",
    "        metrics_F_df = metrics_F_df.append(pd.Series([seed, label] + metrics_F, index=cols), ignore_index=True)\n",
    "        metrics_all_df = metrics_all_df.append(pd.Series([seed, label] + metrics_all, index=cols), ignore_index=True)\n",
    "    \n",
    "    # Calculate and append the \"All Label\" row\n",
    "    metrics_M_average = np.mean(metrics_M_all_label, axis=0).tolist()\n",
    "    metrics_F_average = np.mean(metrics_F_all_label, axis=0).tolist()\n",
    "    metrics_all_average = np.mean(metrics_all_all_label, axis=0).tolist()\n",
    "    \n",
    "    metrics_M_df = metrics_M_df.append(pd.Series([seed, \"All Label\"] + metrics_M_average, index=cols), ignore_index=True)\n",
    "    metrics_F_df = metrics_F_df.append(pd.Series([seed, \"All Label\"] + metrics_F_average, index=cols), ignore_index=True)\n",
    "    metrics_all_df = metrics_all_df.append(pd.Series([seed, \"All Label\"] + metrics_all_average, index=cols), ignore_index=True)\n",
    "\n",
    "# Save the metrics DataFrames to CSV\n",
    "metrics_M_df.to_csv(parent + \"25variation/results/aggregate/analysis/csv/metrics_M_all.csv\", index=False)\n",
    "metrics_F_df.to_csv(parent + \"25variation/results/aggregate/analysis/csv/metrics_F_all.csv\", index=False)\n",
    "metrics_all_df.to_csv(parent + \"25variation/results/aggregate/analysis/csv/metrics_all_all.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Statistical analysis M vs F -> average, CI, and T-test, creation of aggregate_MF_stats.csv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_rel, t\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# Define paths and labels\n",
    "parent = '/home/jkim/research/peds_cxr/'\n",
    "labels = [\"All Label\", \"No Finding\", \"Cardiomegaly\", \"Consolidation\", \"Infiltration\", \"Mass/Nodule\", \"Pneumonia\"]\n",
    "\n",
    "# Load the CSV files\n",
    "df_metrics_M = pd.read_csv(parent + \"25variation/results/aggregate/analysis/csv/metrics_M_all.csv\")\n",
    "df_metrics_F = pd.read_csv(parent + \"25variation/results/aggregate/analysis/csv/metrics_F_all.csv\")\n",
    "df_metrics_all = pd.read_csv(parent + \"25variation/results/aggregate/analysis/csv/metrics_all_all.csv\")\n",
    "\n",
    "# Function to calculate the mean and 95% CI for a given metric and label\n",
    "def calc_mean_and_ci(metric_values):\n",
    "    mean_value = np.mean(metric_values)\n",
    "    stderr = np.std(metric_values, ddof=1) / np.sqrt(len(metric_values))\n",
    "    ci = stderr * t.ppf((1 + 0.95) / 2., len(metric_values) - 1)\n",
    "    return mean_value, (mean_value - ci, mean_value + ci)\n",
    "\n",
    "# List of metrics to analyze\n",
    "metrics_to_analyze = ['AUROC', 'Sensitivity', 'Specificity', 'PPV', 'NPV', 'F1 Score', 'FPR', 'FNR']\n",
    "\n",
    "# Collect p-values for later adjustment\n",
    "p_values = []\n",
    "comparison_labels = []  # Keep track of comparisons for assigning corrected p-values\n",
    "\n",
    "# Calculate p-values for all comparisons\n",
    "for metric in metrics_to_analyze:\n",
    "    for label in labels:\n",
    "        metric_values_M = df_metrics_M[df_metrics_M['Label'] == label][metric].dropna()\n",
    "        metric_values_F = df_metrics_F[df_metrics_F['Label'] == label][metric].dropna()\n",
    "        \n",
    "        if len(metric_values_M) > 0 and len(metric_values_F) > 0:\n",
    "            _, p_value = ttest_rel(metric_values_M, metric_values_F)\n",
    "            p_values.append(p_value)\n",
    "            comparison_labels.append((metric, label))\n",
    "\n",
    "        else: \n",
    "            print(f\"No data for label {label} and metric {metric}\")\n",
    "\n",
    "# Apply the Benjamini-Hochberg correction\n",
    "_, pvals_corrected, _, _ = multipletests(p_values, alpha=0.05, method='fdr_bh')\n",
    "\n",
    "# Initialize empty DataFrame for storing summary stats\n",
    "summary_cols = ['Metric', 'Label', 'Mean_All', 'CI_All', 'Mean_F', 'CI_F', 'Mean_M', 'CI_M', 'p_value_before_BH', 'p_value_after_BH']\n",
    "stats_df = pd.DataFrame(columns=summary_cols)\n",
    "\n",
    "# Fill in the DataFrame with means, CIs, and both sets of p-values\n",
    "for i, (metric, label) in enumerate(comparison_labels):\n",
    "    metric_values_M = df_metrics_M[df_metrics_M['Label'] == label][metric].dropna()\n",
    "    metric_values_F = df_metrics_F[df_metrics_F['Label'] == label][metric].dropna()\n",
    "    metric_values_all = df_metrics_all[df_metrics_all['Label'] == label][metric].dropna()\n",
    "\n",
    "    mean_M, ci_M = calc_mean_and_ci(metric_values_M)\n",
    "    mean_F, ci_F = calc_mean_and_ci(metric_values_F)\n",
    "    mean_all, ci_all = calc_mean_and_ci(metric_values_all)\n",
    "\n",
    "    stats_df = stats_df.append({\n",
    "        'Metric': metric,\n",
    "        'Label': label,\n",
    "        'Mean_All': mean_all,\n",
    "        'CI_All': ci_all,\n",
    "        'Mean_F': mean_F,\n",
    "        'CI_F': ci_F,\n",
    "        'Mean_M': mean_M,\n",
    "        'CI_M': ci_M,\n",
    "        'p_value_before_BH': p_values[i],\n",
    "        'p_value_after_BH': pvals_corrected[i]\n",
    "    }, ignore_index=True)\n",
    "\n",
    "# Calculate clinical significance based on the absolute percentage difference\n",
    "stats_df['abs_percent_diff'] = abs((stats_df['Mean_M'] - stats_df['Mean_F']) / stats_df['Mean_M']) * 100\n",
    "stats_df['clinical_significance_1%'] = (stats_df['abs_percent_diff'] > 1).astype(int)\n",
    "stats_df['clinical_significance_3%'] = (stats_df['abs_percent_diff'] > 3).astype(int)\n",
    "stats_df['clinical_significance_5%'] = (stats_df['abs_percent_diff'] > 5).astype(int)\n",
    "\n",
    "# Save the summary DataFrame to CSV\n",
    "stats_df.to_csv(parent + \"25variation/results/aggregate/analysis/csv/aggregate_MF_stats.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statannot import add_stat_annotation\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "parent = '/home/jkim/research/peds_cxr/'\n",
    "\n",
    "# Define paths and read the CSV files\n",
    "aggregate_MF_stats = pd.read_csv(parent + \"25variation/results/aggregate/analysis/csv/aggregate_MF_stats.csv\")\n",
    "metrics_F_all = pd.read_csv(parent + \"25variation/results/aggregate/analysis/csv/metrics_F_all.csv\")\n",
    "metrics_M_all = pd.read_csv(parent + \"25variation/results/aggregate/analysis/csv/metrics_M_all.csv\")\n",
    "\n",
    "# Add sex column to metrics dataframes and combine them\n",
    "metrics_F_all['Sex'] = 'Female'\n",
    "metrics_M_all['Sex'] = 'Male'\n",
    "combined_metrics = pd.concat([metrics_F_all, metrics_M_all])\n",
    "\n",
    "# Extract unique metrics and labels\n",
    "unique_metrics = aggregate_MF_stats['Metric'].unique()\n",
    "unique_labels = [\"No Finding\", \"Cardiomegaly\", \"Consolidation\", \"Infiltration\", \"Mass/Nodule\", \"Pneumonia\"]\n",
    "neutral_palette = [\"#b5d1ae\", \"#1b485e\"]\n",
    "\n",
    "for metric in unique_metrics:\n",
    "    fig, ax = plt.subplots(figsize=(16, 8))\n",
    "    sns.boxplot(x='Label', y=metric, hue='Sex', data=combined_metrics, ax=ax, order=unique_labels, palette=neutral_palette, width=0.4)\n",
    "    \n",
    "    # Other plot adjustments\n",
    "    ax.set_xlabel('Labels', fontsize=16, fontweight='bold')\n",
    "    ax.set_ylabel(metric, fontsize=16, fontweight='bold')\n",
    "    ax.tick_params(axis='x', labelsize=14, rotation=45)\n",
    "    ax.tick_params(axis='y', labelsize=14)\n",
    "    ax.grid(True, linestyle='--', linewidth=0.5, color='gray', axis='y')\n",
    "\n",
    "    # Prepare a list of tuples for box_pairs\n",
    "    box_pairs = [((label, 'Female'),(label, 'Male')) for label in unique_labels]\n",
    "    \n",
    "    # Extract p-values for each label and metric combination\n",
    "    p_values = [aggregate_MF_stats[(aggregate_MF_stats['Metric'] == metric) & \n",
    "                                    (aggregate_MF_stats['Label'] == label)]['p_value_after_BH'].values[0] \n",
    "                for label in unique_labels]\n",
    "    \n",
    "    # Add statistical annotation\n",
    "    add_stat_annotation(ax, data=combined_metrics, x='Label', y=metric, hue='Sex',\n",
    "                        box_pairs=box_pairs, perform_stat_test=False, pvalues=p_values, \n",
    "                        test_short_name='Custom', loc='inside', verbose=2, \n",
    "                        pvalue_thresholds=[(0.001, '***'), (0.01, '**'), (0.05, '*'), (1, 'ns')])\n",
    "    \n",
    "    ax.legend(title='Sex', title_fontsize='13', fontsize='12', loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "    # Save the plot\n",
    "    plt.tight_layout()\n",
    "    plot_file_path = parent + f'25variation/results/aggregate/analysis/plot/MF/{metric}_comparison.jpeg'\n",
    "    plt.savefig(plot_file_path, format='jpeg')\n",
    "    plt.show()\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
